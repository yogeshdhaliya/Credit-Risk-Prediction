{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Load Clean Data & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n",
      "Loading features from: /Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/data/processed/X_cleaned.csv\n",
      "Loading target from: /Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/data/processed/y_target.csv\n",
      "\n",
      "--- Data Loaded Successfully ---\n",
      "\n",
      "--- X (Features) Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 51336 entries, 1 to 51336\n",
      "Data columns (total 58 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tot_enq                     45015 non-null  float64\n",
      " 1   CC_enq                      45015 non-null  float64\n",
      " 2   CC_enq_L6m                  45015 non-null  float64\n",
      " 3   CC_enq_L12m                 45015 non-null  float64\n",
      " 4   PL_enq                      45015 non-null  float64\n",
      " 5   PL_enq_L6m                  45015 non-null  float64\n",
      " 6   PL_enq_L12m                 45015 non-null  float64\n",
      " 7   time_since_recent_enq       45015 non-null  float64\n",
      " 8   enq_L12m                    45015 non-null  float64\n",
      " 9   enq_L6m                     45015 non-null  float64\n",
      " 10  enq_L3m                     45015 non-null  float64\n",
      " 11  MARITALSTATUS               51336 non-null  object \n",
      " 12  EDUCATION                   51336 non-null  object \n",
      " 13  AGE                         51336 non-null  int64  \n",
      " 14  GENDER                      51336 non-null  object \n",
      " 15  NETMONTHLYINCOME            51336 non-null  int64  \n",
      " 16  Time_With_Curr_Empr         51336 non-null  int64  \n",
      " 17  pct_of_active_TLs_ever      51336 non-null  float64\n",
      " 18  pct_opened_TLs_L6m_of_L12m  51336 non-null  float64\n",
      " 19  pct_currentBal_all_TL       51264 non-null  float64\n",
      " 20  CC_utilization              3700 non-null   float64\n",
      " 21  CC_Flag                     51336 non-null  int64  \n",
      " 22  PL_utilization              6901 non-null   float64\n",
      " 23  PL_Flag                     51336 non-null  int64  \n",
      " 24  pct_PL_enq_L6m_of_L12m      51336 non-null  float64\n",
      " 25  pct_CC_enq_L6m_of_L12m      51336 non-null  float64\n",
      " 26  pct_PL_enq_L6m_of_ever      51336 non-null  float64\n",
      " 27  pct_CC_enq_L6m_of_ever      51336 non-null  float64\n",
      " 28  max_unsec_exposure_inPct    28158 non-null  float64\n",
      " 29  HL_Flag                     51336 non-null  int64  \n",
      " 30  GL_Flag                     51336 non-null  int64  \n",
      " 31  last_prod_enq2              51336 non-null  object \n",
      " 32  first_prod_enq2             51336 non-null  object \n",
      " 33  Total_TL                    51336 non-null  int64  \n",
      " 34  Tot_Closed_TL               51336 non-null  int64  \n",
      " 35  Tot_Active_TL               51336 non-null  int64  \n",
      " 36  Total_TL_opened_L6M         51336 non-null  int64  \n",
      " 37  Tot_TL_closed_L6M           51336 non-null  int64  \n",
      " 38  pct_tl_open_L6M             51336 non-null  float64\n",
      " 39  pct_tl_closed_L6M           51336 non-null  float64\n",
      " 40  pct_active_tl               51336 non-null  float64\n",
      " 41  pct_closed_tl               51336 non-null  float64\n",
      " 42  Total_TL_opened_L12M        51336 non-null  int64  \n",
      " 43  Tot_TL_closed_L12M          51336 non-null  int64  \n",
      " 44  pct_tl_open_L12M            51336 non-null  float64\n",
      " 45  pct_tl_closed_L12M          51336 non-null  float64\n",
      " 46  Tot_Missed_Pmnt             51336 non-null  int64  \n",
      " 47  Auto_TL                     51336 non-null  int64  \n",
      " 48  CC_TL                       51336 non-null  int64  \n",
      " 49  Consumer_TL                 51336 non-null  int64  \n",
      " 50  Gold_TL                     51336 non-null  int64  \n",
      " 51  Home_TL                     51336 non-null  int64  \n",
      " 52  PL_TL                       51336 non-null  int64  \n",
      " 53  Secured_TL                  51336 non-null  int64  \n",
      " 54  Unsecured_TL                51336 non-null  int64  \n",
      " 55  Other_TL                    51336 non-null  int64  \n",
      " 56  Age_Oldest_TL               51296 non-null  float64\n",
      " 57  Age_Newest_TL               51296 non-null  float64\n",
      "dtypes: float64(29), int64(24), object(5)\n",
      "memory usage: 23.1+ MB\n",
      "\n",
      "--- y (Target) Imbalance (Finding 4) ---\n",
      "Approved_Flag\n",
      "P1    0.113040\n",
      "P2    0.627221\n",
      "P3    0.145161\n",
      "P4    0.114578\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport \n",
    "import warnings\n",
    "\n",
    "# --- Setup ---\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"Libraries imported.\")\n",
    "\n",
    "# --- Load Processed Data ---\n",
    "\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "PROCESSED_DATA_DIR = os.path.join(ROOT_DIR, 'data', 'processed')\n",
    "\n",
    "X_path = os.path.join(PROCESSED_DATA_DIR, 'X_cleaned.csv')\n",
    "y_path = os.path.join(PROCESSED_DATA_DIR, 'y_target.csv')\n",
    "\n",
    "print(f\"Loading features from: {X_path}\")\n",
    "print(f\"Loading target from: {y_path}\")\n",
    "\n",
    "try:\n",
    "    # Load features, ensuring PROSPECTID is our index\n",
    "    X = pd.read_csv(X_path, index_col='PROSPECTID')\n",
    "    \n",
    "    # Load target, set index, and use .squeeze() to turn it into a Series\n",
    "    y = pd.read_csv(y_path, index_col='PROSPECTID').squeeze('columns')\n",
    "    \n",
    "    print(\"\\n--- Data Loaded Successfully ---\")\n",
    "    \n",
    "    # --- Verification Step ---\n",
    "    print(\"\\n--- X (Features) Info ---\")\n",
    "    X.info()\n",
    "    \n",
    "    print(f\"\\n--- y (Target) Imbalance (Finding 4) ---\")\n",
    "    print(y.value_counts(normalize=True).sort_index())\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n[ERROR] Files not found. Did you complete Phase 1?\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Full Data Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataframe for profiling. Shape: (51336, 59)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05d7169ae9149dfae3d6d0074f62a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yogeshdhaliya/anaconda3/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/venv/lib/python3.11/site-packages/tqdm/_monitor.py\", line 84, in run\n",
      "    instance.refresh(nolock=True)\n",
      "  File \"/Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/venv/lib/python3.11/site-packages/tqdm/std.py\", line 1347, in refresh\n",
      "    self.display()\n",
      "  File \"/Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/venv/lib/python3.11/site-packages/tqdm/notebook.py\", line 171, in display\n",
      "    rtext.value = right\n",
      "    ^^^^^^^^^^^\n",
      "  File \"/Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/venv/lib/python3.11/site-packages/traitlets/traitlets.py\", line 716, in __set__\n",
      "    self.set(obj, value)\n",
      "  File \"/Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/venv/lib/python3.11/site-packages/traitlets/traitlets.py\", line 706, in set\n",
      "    obj._notify_trait(self.name, old_value, new_value)\n",
      "  File \"/Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/venv/lib/python3.11/site-packages/traitlets/traitlets.py\", line 1513, in _notify_trait\n",
      "    self.notify_change(\n",
      "  File \"/Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/venv/lib/python3.11/site-packages/ipywidgets/widgets/widget.py\", line 700, in notify_change\n",
      "    self.send_state(key=name)\n",
      "  File \"/Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/venv/lib/python3.11/site-packages/ipywidgets/widgets/widget.py\", line 586, in send_state\n",
      "    self._send(msg, buffers=buffers)\n",
      "  File \"/Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/venv/lib/python3.11/site-packages/ipywidgets/widgets/widget.py\", line 825, in _send\n",
      "    self.comm.send(data=msg, buffers=buffers)\n",
      "  File \"/Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/venv/lib/python3.11/site-packages/comm/base_comm.py\", line 144, in send\n",
      "    self.publish_msg(\n",
      "  File \"/Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/venv/lib/python3.11/site-packages/ipykernel/comm/comm.py\", line 42, in publish_msg\n",
      "    parent=self.kernel.get_parent(),\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 797, in get_parent\n",
      "    return self._shell_parent.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='shell_parent' at 0x10447fba0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c682e30e4894ad18ad78f071fb2a12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb130a8e33c4b63b54d7c42617c909d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3fea4307e424d918eac11400fe7ce41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SUCCESS! ---\n",
      "Full data profile has been generated and saved to:\n",
      "/Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/notebooks/credit_risk_profile.html\n",
      "\n",
      "Please open this file in your browser to explore the data.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Combine X and y for Profiling ---\n",
    "# The profiler works best when it can see features and target together\n",
    "df_for_profiling = X.copy()\n",
    "df_for_profiling[y.name] = y\n",
    "\n",
    "print(f\"Combined dataframe for profiling. Shape: {df_for_profiling.shape}\")\n",
    "\n",
    "# --- 2. Generate the Profile Report ---\n",
    "profile = ProfileReport(\n",
    "    df_for_profiling, \n",
    "    title=\"Credit Risk Data Profile (Phase 2)\",\n",
    "    explorative=True\n",
    ")\n",
    "\n",
    "# --- 3. Save Report to File ---\n",
    "# We save to an HTML file in the *current* /notebooks folder.\n",
    "# This avoids flooding the notebook with a huge output.\n",
    "profile_path = os.path.join(os.getcwd(), 'credit_risk_profile.html')\n",
    "profile.to_file(profile_path)\n",
    "\n",
    "print(f\"\\n--- SUCCESS! ---\")\n",
    "print(f\"Full data profile has been generated and saved to:\")\n",
    "print(f\"{profile_path}\")\n",
    "print(\"\\nPlease open this file in your browser to explore the data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Categorical Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 5 categorical columns.\n",
      "Identified 53 numerical columns.\n",
      "\n",
      "--- Finding 3: Ordinal Feature Check ('EDUCATION') ---\n",
      "EDUCATION\n",
      "GRADUATE          16673\n",
      "12TH              14467\n",
      "SSC                9276\n",
      "UNDER GRADUATE     5492\n",
      "OTHERS             2917\n",
      "POST-GRADUATE      2242\n",
      "PROFESSIONAL        269\n",
      "Name: count, dtype: int64\n",
      "=> CONFIRMED: 'EDUCATION' has a clear order (OTHERS < 12TH < SSC < GRADUATE < PROFESSIONAL). This is ordinal.\n",
      "\n",
      "--- Nominal Feature Check (Others) ---\n",
      "\n",
      "--- Feature: 'MARITALSTATUS' ---\n",
      "MARITALSTATUS\n",
      "Married    37752\n",
      "Single     13584\n",
      "Name: count, dtype: int64\n",
      "=> CONFIRMED: 'MARITALSTATUS' has no inherent order. This is nominal.\n",
      "\n",
      "--- Feature: 'GENDER' ---\n",
      "GENDER\n",
      "M    45245\n",
      "F     6091\n",
      "Name: count, dtype: int64\n",
      "=> CONFIRMED: 'GENDER' has no inherent order. This is nominal.\n",
      "\n",
      "--- Feature: 'last_prod_enq2' ---\n",
      "last_prod_enq2\n",
      "others          20831\n",
      "ConsumerLoan    17793\n",
      "PL               7959\n",
      "CC               2339\n",
      "AL               1511\n",
      "HL                903\n",
      "Name: count, dtype: int64\n",
      "=> CONFIRMED: 'last_prod_enq2' has no inherent order. This is nominal.\n",
      "\n",
      "--- Feature: 'first_prod_enq2' ---\n",
      "first_prod_enq2\n",
      "others          28120\n",
      "ConsumerLoan    11860\n",
      "PL               4889\n",
      "AL               2870\n",
      "CC               2188\n",
      "HL               1409\n",
      "Name: count, dtype: int64\n",
      "=> CONFIRMED: 'first_prod_enq2' has no inherent order. This is nominal.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define our column lists based on X.info() ---\n",
    "categorical_cols = [\n",
    "    'MARITALSTATUS', \n",
    "    'EDUCATION', \n",
    "    'GENDER', \n",
    "    'last_prod_enq2', \n",
    "    'first_prod_enq2'\n",
    "]\n",
    "\n",
    "# Numerical cols are everything else\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "print(f\"Identified {len(categorical_cols)} categorical columns.\")\n",
    "print(f\"Identified {len(numerical_cols)} numerical columns.\")\n",
    "\n",
    "# --- 2. Validate Finding 3: Ordinal vs. Nominal ---\n",
    "\n",
    "# First, inspect 'EDUCATION' to confirm its ordinal nature\n",
    "print(\"\\n--- Finding 3: Ordinal Feature Check ('EDUCATION') ---\")\n",
    "print(X['EDUCATION'].value_counts())\n",
    "print(\"=> CONFIRMED: 'EDUCATION' has a clear order (SSC/OTHERS < 12TH < GRADUATE < POST GRADUATE < PROFESSIONAL). This is ordinal.\")\n",
    "\n",
    "# Next, inspect the remaining nominal features\n",
    "print(\"\\n--- Nominal Feature Check (Others) ---\")\n",
    "for col in categorical_cols:\n",
    "    if col != 'EDUCATION':\n",
    "        print(f\"\\n--- Feature: '{col}' ---\")\n",
    "        print(X[col].value_counts())\n",
    "        print(f\"=> CONFIRMED: '{col}' has no inherent order. This is nominal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Statistical Test (Categorical vs. Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chi-Square Test (Categorical vs. Target) ---\n",
      "Null Hypothesis: Feature is independent of the Target (Approved_Flag)\n",
      "We are looking for a p-value < 0.05 to reject the null.\n",
      "\n",
      "           Feature  Chi2 Statistic        p-value\n",
      "3   last_prod_enq2     3728.514629   0.000000e+00\n",
      "4  first_prod_enq2     1833.116465   0.000000e+00\n",
      "0    MARITALSTATUS     1188.129358  2.758830e-257\n",
      "1        EDUCATION      225.246136   8.464676e-38\n",
      "2           GENDER       19.229726   2.450668e-04\n",
      "\n",
      "=> Interpretation: Features with very low p-values are statistically significant predictors.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "print(\"\\n--- Chi-Square Test (Categorical vs. Target) ---\")\n",
    "print(\"Null Hypothesis: Feature is independent of the Target (Approved_Flag)\")\n",
    "print(\"We are looking for a p-value < 0.05 to reject the null.\\n\")\n",
    "\n",
    "chi2_results = []\n",
    "for col in categorical_cols:\n",
    "    # Create a contingency table (crosstab)\n",
    "    contingency_table = pd.crosstab(X[col], y)\n",
    "    \n",
    "    # Run the test\n",
    "    chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "    \n",
    "    chi2_results.append({\n",
    "        'Feature': col,\n",
    "        'Chi2 Statistic': chi2_stat,\n",
    "        'p-value': p_value\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "df_chi2 = pd.DataFrame(chi2_results).sort_values(by='p-value', ascending=True)\n",
    "print(df_chi2)\n",
    "print(\"\\n=> Interpretation: Features with very low p-values are statistically significant predictors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Numerical Feature Analysis (Stats & Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Numerical Features: Descriptive Statistics ---\n",
      "                              count          mean           std   min  \\\n",
      "tot_enq                     45015.0      5.291036      6.178414   1.0   \n",
      "CC_enq                      45015.0      0.467266      1.666951   0.0   \n",
      "CC_enq_L6m                  45015.0      0.158903      0.673070   0.0   \n",
      "CC_enq_L12m                 45015.0      0.260846      0.998968   0.0   \n",
      "PL_enq                      45015.0      1.135177      2.330629   0.0   \n",
      "PL_enq_L6m                  45015.0      0.506720      1.353613   0.0   \n",
      "PL_enq_L12m                 45015.0      0.757659      1.769592   0.0   \n",
      "time_since_recent_enq       45015.0    260.051649    462.042665   0.0   \n",
      "enq_L12m                    45015.0      3.011107      4.218634   0.0   \n",
      "enq_L6m                     45015.0      1.995290      3.121818   0.0   \n",
      "enq_L3m                     45015.0      1.241719      2.063165   0.0   \n",
      "AGE                         51336.0     33.758532      8.816364  21.0   \n",
      "NETMONTHLYINCOME            51336.0  26424.185640  20027.108841   0.0   \n",
      "Time_With_Curr_Empr         51336.0    110.707846     76.046831   0.0   \n",
      "pct_of_active_TLs_ever      51336.0      0.577542      0.379867   0.0   \n",
      "pct_opened_TLs_L6m_of_L12m  51336.0      0.302955      0.406049   0.0   \n",
      "pct_currentBal_all_TL       51264.0      0.836152     36.828156   0.0   \n",
      "CC_utilization               3700.0      0.628344      1.237861   0.0   \n",
      "CC_Flag                     51336.0      0.089469      0.285423   0.0   \n",
      "PL_utilization               6901.0      0.751838      0.253933   0.0   \n",
      "PL_Flag                     51336.0      0.167874      0.373758   0.0   \n",
      "pct_PL_enq_L6m_of_L12m      51336.0      0.190414      0.376218   0.0   \n",
      "pct_CC_enq_L6m_of_L12m      51336.0      0.065182      0.235706   0.0   \n",
      "pct_PL_enq_L6m_of_ever      51336.0      0.170492      0.350209   0.0   \n",
      "pct_CC_enq_L6m_of_ever      51336.0      0.056302      0.213506   0.0   \n",
      "max_unsec_exposure_inPct    28158.0     38.664235   1498.955157   0.0   \n",
      "HL_Flag                     51336.0      0.271116      0.444540   0.0   \n",
      "GL_Flag                     51336.0      0.052887      0.223810   0.0   \n",
      "Total_TL                    51336.0      4.858598      7.177116   1.0   \n",
      "Tot_Closed_TL               51336.0      2.770415      5.941680   0.0   \n",
      "Tot_Active_TL               51336.0      2.088184      2.290774   0.0   \n",
      "Total_TL_opened_L6M         51336.0      0.736754      1.296717   0.0   \n",
      "Tot_TL_closed_L6M           51336.0      0.428919      0.989972   0.0   \n",
      "pct_tl_open_L6M             51336.0      0.184574      0.297414   0.0   \n",
      "pct_tl_closed_L6M           51336.0      0.089095      0.205635   0.0   \n",
      "pct_active_tl               51336.0      0.577542      0.379867   0.0   \n",
      "pct_closed_tl               51336.0      0.422458      0.379867   0.0   \n",
      "Total_TL_opened_L12M        51336.0      1.503701      2.119399   0.0   \n",
      "Tot_TL_closed_L12M          51336.0      0.736851      1.454120   0.0   \n",
      "pct_tl_open_L12M            51336.0      0.395184      0.391930   0.0   \n",
      "pct_tl_closed_L12M          51336.0      0.149989      0.257267   0.0   \n",
      "Tot_Missed_Pmnt             51336.0      0.546751      1.085529   0.0   \n",
      "Auto_TL                     51336.0      0.593268      0.900585   0.0   \n",
      "CC_TL                       51336.0      0.124981      0.505201   0.0   \n",
      "Consumer_TL                 51336.0      1.136084      2.227997   0.0   \n",
      "Gold_TL                     51336.0      1.561847      5.376434   0.0   \n",
      "Home_TL                     51336.0      0.070146      0.340861   0.0   \n",
      "PL_TL                       51336.0      0.282511      0.858168   0.0   \n",
      "Secured_TL                  51336.0      2.844904      6.187177   0.0   \n",
      "Unsecured_TL                51336.0      2.013694      3.198322   0.0   \n",
      "Other_TL                    51336.0      1.089762      2.417496   0.0   \n",
      "Age_Oldest_TL               51296.0     45.376969     41.737151   0.0   \n",
      "Age_Newest_TL               51296.0     15.780022     21.995676   0.0   \n",
      "\n",
      "                                   25%         50%        75%          max  \n",
      "tot_enq                         2.0000      3.0000      6.000      176.000  \n",
      "CC_enq                          0.0000      0.0000      0.000       42.000  \n",
      "CC_enq_L6m                      0.0000      0.0000      0.000       17.000  \n",
      "CC_enq_L12m                     0.0000      0.0000      0.000       24.000  \n",
      "PL_enq                          0.0000      0.0000      1.000       46.000  \n",
      "PL_enq_L6m                      0.0000      0.0000      0.000       44.000  \n",
      "PL_enq_L12m                     0.0000      0.0000      1.000       44.000  \n",
      "time_since_recent_enq           8.0000     75.0000    295.000     4768.000  \n",
      "enq_L12m                        1.0000      2.0000      4.000       87.000  \n",
      "enq_L6m                         0.0000      1.0000      3.000       66.000  \n",
      "enq_L3m                         0.0000      1.0000      2.000       42.000  \n",
      "AGE                            27.0000     32.0000     39.000       77.000  \n",
      "NETMONTHLYINCOME            18000.0000  23000.0000  30000.000  2500000.000  \n",
      "Time_With_Curr_Empr            61.0000     93.0000    131.000     1020.000  \n",
      "pct_of_active_TLs_ever          0.2500      0.5560      1.000        1.000  \n",
      "pct_opened_TLs_L6m_of_L12m      0.0000      0.0000      0.643        1.000  \n",
      "pct_currentBal_all_TL           0.0870      0.6180      0.889     6327.500  \n",
      "CC_utilization                  0.1865      0.7385      0.964       71.059  \n",
      "CC_Flag                         0.0000      0.0000      0.000        1.000  \n",
      "PL_utilization                  0.6410      0.8350      0.944        1.708  \n",
      "PL_Flag                         0.0000      0.0000      0.000        1.000  \n",
      "pct_PL_enq_L6m_of_L12m          0.0000      0.0000      0.000        1.000  \n",
      "pct_CC_enq_L6m_of_L12m          0.0000      0.0000      0.000        1.000  \n",
      "pct_PL_enq_L6m_of_ever          0.0000      0.0000      0.000        1.000  \n",
      "pct_CC_enq_L6m_of_ever          0.0000      0.0000      0.000        1.000  \n",
      "max_unsec_exposure_inPct        0.7750      1.8200      5.283   173800.000  \n",
      "HL_Flag                         0.0000      0.0000      1.000        1.000  \n",
      "GL_Flag                         0.0000      0.0000      0.000        1.000  \n",
      "Total_TL                        1.0000      2.0000      5.000      235.000  \n",
      "Tot_Closed_TL                   0.0000      1.0000      3.000      216.000  \n",
      "Tot_Active_TL                   1.0000      1.0000      3.000       47.000  \n",
      "Total_TL_opened_L6M             0.0000      0.0000      1.000       27.000  \n",
      "Tot_TL_closed_L6M               0.0000      0.0000      1.000       19.000  \n",
      "pct_tl_open_L6M                 0.0000      0.0000      0.308        1.000  \n",
      "pct_tl_closed_L6M               0.0000      0.0000      0.053        1.000  \n",
      "pct_active_tl                   0.2500      0.5560      1.000        1.000  \n",
      "pct_closed_tl                   0.0000      0.4440      0.750        1.000  \n",
      "Total_TL_opened_L12M            0.0000      1.0000      2.000       39.000  \n",
      "Tot_TL_closed_L12M              0.0000      0.0000      1.000       39.000  \n",
      "pct_tl_open_L12M                0.0000      0.3330      0.750        1.000  \n",
      "pct_tl_closed_L12M              0.0000      0.0000      0.250        1.000  \n",
      "Tot_Missed_Pmnt                 0.0000      0.0000      1.000       34.000  \n",
      "Auto_TL                         0.0000      0.0000      1.000       27.000  \n",
      "CC_TL                           0.0000      0.0000      0.000       27.000  \n",
      "Consumer_TL                     0.0000      0.0000      1.000       41.000  \n",
      "Gold_TL                         0.0000      0.0000      1.000      235.000  \n",
      "Home_TL                         0.0000      0.0000      0.000       10.000  \n",
      "PL_TL                           0.0000      0.0000      0.000       29.000  \n",
      "Secured_TL                      0.0000      1.0000      3.000      235.000  \n",
      "Unsecured_TL                    0.0000      1.0000      2.000       55.000  \n",
      "Other_TL                        0.0000      0.0000      1.000       80.000  \n",
      "Age_Oldest_TL                  14.0000     33.0000     64.000      392.000  \n",
      "Age_Newest_TL                   4.0000      8.0000     17.000      392.000  \n",
      "\n",
      "--- Visualizing Key Numerical Distributions ---\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Descriptive Statistics ---\n",
    "print(\"\\n--- Numerical Features: Descriptive Statistics ---\")\n",
    "# .T transposes the output to be more readable\n",
    "print(X[numerical_cols].describe().T)\n",
    "\n",
    "# --- 2. Visualize Key Distributions ---\n",
    "print(\"\\n--- Visualizing Key Numerical Distributions ---\")\n",
    "\n",
    "# Plot AGE\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.kdeplot(data=X, x='AGE', hue=y, common_norm=False, fill=True)\n",
    "plt.title('Distribution of AGE by Risk Category', fontsize=16)\n",
    "plt.xlabel('Age')\n",
    "plt.show()\n",
    "\n",
    "# Plot NETMONTHLYINCOME\n",
    "# This will be very skewed, so we'll plot its log-transform\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Use np.log1p(x) which is log(1+x) to handle any zero incomes\n",
    "sns.kdeplot(data=X, x=np.log1p(X['NETMONTHLYINCOME']), hue=y, common_norm=False, fill=True)\n",
    "plt.title('Distribution of Log(NETMONTHLYINCOME) by Risk Category', fontsize=16)\n",
    "plt.xlabel('Log(Net Monthly Income)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: Statistical Test (Numerical vs. Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ANOVA F-Test (Numerical vs. Target) ---\n",
      "Null Hypothesis: The mean of the feature is the same for all target classes (P1-P4)\n",
      "We are looking for a p-value < 0.05 to reject the null.\n",
      "\n",
      "                       Feature  F-Statistic        p-value\n",
      "0                      tot_enq  1690.485944   0.000000e+00\n",
      "28                    Total_TL  1190.662645   0.000000e+00\n",
      "24      pct_CC_enq_L6m_of_ever   770.204842   0.000000e+00\n",
      "23      pct_PL_enq_L6m_of_ever  3672.838162   0.000000e+00\n",
      "22      pct_CC_enq_L6m_of_L12m   777.634453   0.000000e+00\n",
      "21      pct_PL_enq_L6m_of_L12m  3530.225183   0.000000e+00\n",
      "29               Tot_Closed_TL  1019.098298   0.000000e+00\n",
      "30               Tot_Active_TL   649.567886   0.000000e+00\n",
      "33             pct_tl_open_L6M   941.447777   0.000000e+00\n",
      "35               pct_active_tl   513.974136   0.000000e+00\n",
      "36               pct_closed_tl   513.974136   0.000000e+00\n",
      "39            pct_tl_open_L12M   967.962159   0.000000e+00\n",
      "14      pct_of_active_TLs_ever   513.974136   0.000000e+00\n",
      "46                     Home_TL   587.182172   0.000000e+00\n",
      "48                  Secured_TL  1060.442049   0.000000e+00\n",
      "11                         AGE  1261.751112   0.000000e+00\n",
      "10                     enq_L3m  7894.169459   0.000000e+00\n",
      "9                      enq_L6m  5576.042087   0.000000e+00\n",
      "8                     enq_L12m  3996.751389   0.000000e+00\n",
      "7        time_since_recent_enq  1934.572352   0.000000e+00\n",
      "6                  PL_enq_L12m  1965.377150   0.000000e+00\n",
      "5                   PL_enq_L6m  2668.969305   0.000000e+00\n",
      "4                       PL_enq  1088.785176   0.000000e+00\n",
      "3                  CC_enq_L12m   649.786681   0.000000e+00\n",
      "2                   CC_enq_L6m   809.816363   0.000000e+00\n",
      "50                    Other_TL  1393.365393   0.000000e+00\n",
      "51               Age_Oldest_TL  7507.001594   0.000000e+00\n",
      "27                     GL_Flag   483.693299  5.630245e-310\n",
      "26                     HL_Flag   482.515462  3.134991e-309\n",
      "31         Total_TL_opened_L6M   449.533493  2.497223e-288\n",
      "13         Time_With_Curr_Empr   437.671150  8.397528e-281\n",
      "47                       PL_TL   427.961192  1.226940e-274\n",
      "42                     Auto_TL   423.019709  1.687905e-271\n",
      "15  pct_opened_TLs_L6m_of_L12m   395.783991  3.476521e-254\n",
      "45                     Gold_TL   395.633429  4.334412e-254\n",
      "41             Tot_Missed_Pmnt   390.388242  9.425733e-251\n",
      "1                       CC_enq   327.214873  3.337541e-210\n",
      "37        Total_TL_opened_L12M   317.302561  3.773879e-204\n",
      "49                Unsecured_TL   282.975201  3.382166e-182\n",
      "20                     PL_Flag   275.776049  1.374632e-177\n",
      "38          Tot_TL_closed_L12M   269.524699  1.386162e-173\n",
      "52               Age_Newest_TL   195.192457  7.044810e-126\n",
      "32           Tot_TL_closed_L6M   129.660498   1.118279e-83\n",
      "44                 Consumer_TL   112.318168   1.721694e-72\n",
      "19              PL_utilization   108.759147   8.406934e-69\n",
      "43                       CC_TL    99.022767   6.560786e-64\n",
      "18                     CC_Flag    89.485212   9.426758e-58\n",
      "34           pct_tl_closed_L6M    70.751296   1.178127e-45\n",
      "40          pct_tl_closed_L12M    58.312026   1.267080e-37\n",
      "12            NETMONTHLYINCOME    47.483568   1.233838e-30\n",
      "17              CC_utilization     3.132865   2.455394e-02\n",
      "16       pct_currentBal_all_TL     0.651237   5.820734e-01\n",
      "25    max_unsec_exposure_inPct     0.576860   6.301618e-01\n",
      "\n",
      "=> Interpretation: Features with very low p-values have means that are\n",
      "   statistically different across the P1-P4 classes.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "print(\"\\n--- ANOVA F-Test (Numerical vs. Target) ---\")\n",
    "print(\"Null Hypothesis: The mean of the feature is the same for all target classes (P1-P4)\")\n",
    "print(\"We are looking for a p-value < 0.05 to reject the null.\\n\")\n",
    "\n",
    "anova_results = []\n",
    "for col in numerical_cols:\n",
    "    # ANOVA cannot handle NaN values, so we must drop them *for the test*\n",
    "    # We create a list of Series, one for each target class\n",
    "    groups = [\n",
    "        X[y == target_class][col].dropna() \n",
    "        for target_class in y.unique()\n",
    "    ]\n",
    "    \n",
    "    # Check if we have data after dropping NaNs\n",
    "    if all(len(g) > 0 for g in groups):\n",
    "        f_stat, p_value = f_oneway(*groups)\n",
    "        anova_results.append({\n",
    "            'Feature': col,\n",
    "            'F-Statistic': f_stat,\n",
    "            'p-value': p_value\n",
    "        })\n",
    "    else:\n",
    "        anova_results.append({\n",
    "            'Feature': col,\n",
    "            'F-Statistic': np.nan,\n",
    "            'p-value': np.nan  # Not enough data to test\n",
    "        })\n",
    "\n",
    "# Display results\n",
    "df_anova = pd.DataFrame(anova_results).sort_values(by='p-value', ascending=True)\n",
    "print(df_anova)\n",
    "print(\"\\n=> Interpretation: Features with very low p-values have means that are\")\n",
    "print(\"   statistically different across the P1-P4 classes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7: Manual Missing Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Missing Data Analysis ---\n",
      "Percentage of missing values per feature (showing only > 0%):\n",
      "CC_utilization              92.792582\n",
      "PL_utilization              86.557192\n",
      "max_unsec_exposure_inPct    45.149603\n",
      "tot_enq                     12.312997\n",
      "CC_enq                      12.312997\n",
      "enq_L3m                     12.312997\n",
      "enq_L6m                     12.312997\n",
      "enq_L12m                    12.312997\n",
      "time_since_recent_enq       12.312997\n",
      "PL_enq_L12m                 12.312997\n",
      "PL_enq_L6m                  12.312997\n",
      "PL_enq                      12.312997\n",
      "CC_enq_L12m                 12.312997\n",
      "CC_enq_L6m                  12.312997\n",
      "pct_currentBal_all_TL        0.140252\n",
      "Age_Oldest_TL                0.077918\n",
      "Age_Newest_TL                0.077918\n",
      "dtype: float64\n",
      "\n",
      "--- Missing Data Groups Identified ---\n",
      "Major Missingness (> 80%): ['CC_utilization', 'PL_utilization']\n",
      "Moderate Missingness (20-80%): ['max_unsec_exposure_inPct']\n",
      "Systematic Missingness (~12%): ['tot_enq', 'CC_enq', 'enq_L3m', 'enq_L6m', 'enq_L12m', 'time_since_recent_enq', 'PL_enq_L12m', 'PL_enq_L6m', 'PL_enq', 'CC_enq_L12m', 'CC_enq_L6m']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Missing Data Analysis ---\")\n",
    "missing_pct = X.isna().mean() * 100\n",
    "missing_pct_sorted = missing_pct[missing_pct > 0].sort_values(ascending=False)\n",
    "\n",
    "print(\"Percentage of missing values per feature (showing only > 0%):\")\n",
    "print(missing_pct_sorted)\n",
    "\n",
    "print(\"\\n--- Missing Data Groups Identified ---\")\n",
    "print(f\"Major Missingness (> 80%): {missing_pct_sorted[missing_pct_sorted > 80].index.tolist()}\")\n",
    "print(f\"Moderate Missingness (20-80%): {missing_pct_sorted[(missing_pct_sorted > 20) & (missing_pct_sorted < 80)].index.tolist()}\")\n",
    "print(f\"Systematic Missingness (~12%): {missing_pct_sorted[(missing_pct_sorted > 10) & (missing_pct_sorted < 20)].index.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8: Feature Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (51336, 58)\n",
      "Dropping 4 columns identified in EDA...\n",
      "New pruned X shape: (51336, 54)\n",
      "\n",
      "--- PHASE 2 COMPLETE ---\n",
      "Pruned X (54 features) saved to: /Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/data/processed/X_cleaned.csv\n",
      "Target y saved to: /Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/data/processed/y_target.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define Columns to Drop (Based on Phase 2 EDA) ---\n",
    "cols_to_drop = [\n",
    "    # Group 1: Major Missingness (>80%)\n",
    "    'CC_utilization',\n",
    "    'PL_utilization',\n",
    "    \n",
    "    # Group 2: Not Statistically Significant (High p-value)\n",
    "    'max_unsec_exposure_inPct',\n",
    "    'pct_currentBal_all_TL'\n",
    "]\n",
    "\n",
    "print(f\"Original X shape: {X.shape}\")\n",
    "print(f\"Dropping {len(cols_to_drop)} columns identified in EDA...\")\n",
    "\n",
    "# --- 2. Drop the Columns ---\n",
    "X_pruned = X.drop(columns=cols_to_drop)\n",
    "\n",
    "print(f\"New pruned X shape: {X_pruned.shape}\")\n",
    "\n",
    "# --- 3. Overwrite Processed Files (Our New Checkpoint) ---\n",
    "# We are overwriting our \"cleaned\" file with this new,\n",
    "# even cleaner, pruned version.\n",
    "X_pruned_path = os.path.join(PROCESSED_DATA_DIR, 'X_cleaned.csv')\n",
    "y_path = os.path.join(PROCESSED_DATA_DIR, 'y_target.csv')\n",
    "\n",
    "X_pruned.to_csv(X_pruned_path)\n",
    "y.to_csv(y_path) # Re-save y as well to keep them paired\n",
    "\n",
    "print(f\"\\n--- PHASE 2 COMPLETE ---\")\n",
    "print(f\"Pruned X (54 features) saved to: {X_pruned_path}\")\n",
    "print(f\"Target y saved to: {y_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase:2 EDA**.\n",
    "\n",
    "Our goal was to deeply analyze the leak-free data, validate our project's Key Findings, and build a clear plan for preprocessing.\n",
    "\n",
    "1.  **Categorical Feature Analysis (Finding 3):**\n",
    "    * We manually inspected all 5 `object` columns (`EDUCATION`, `MARITALSTATUS`, `GENDER`, etc.).\n",
    "    * We validated `EDUCATION` has a clear ordinal structure (which we will custom-map) and the rest are nominal (which we will one-hot encode).\n",
    "    * A **Chi-Square test** proved that all 5 categorical features are **statistically significant** predictors of the target, so we will keep all of them.\n",
    "\n",
    "2.  **Numerical Feature Analysis:**\n",
    "    * We analyzed all 53 numerical features and found **massive outliers** (e.g., in `NETMONTHLYINCOME`). This confirms our decision to use `RobustScaler` (which is not sensitive to outliers) in our pipeline.\n",
    "    * An **ANOVA test** showed that almost all numerical features are **statistically significant**.\n",
    "\n",
    "3.  **Missing Data Strategy & Feature Pruning (Our Main Action):**\n",
    "    * We identified three distinct groups of missing data and created a clear strategy:\n",
    "    * **DROP (Major Missingness):** We dropped `CC_utilization` and `PL_utilization` because they were over 86% missing and unusable.\n",
    "    * **DROP (Not Significant):** We dropped `max_unsec_exposure_inPct` and `pct_currentBal_all_TL` because our ANOVA test showed they had **no statistical relationship** with the target (high p-values).\n",
    "    * **IMPUTE PLAN (for Phase 3):** We confirmed the 11 \"enquiry\" columns should be imputed with `0` (as `NaN` means \"zero enquiries\") and 2 minor \"Age\" columns will be imputed with their `median`.\n",
    "\n",
    "**Final Outcome:** We concluded Phase 2 by saving a new, pruned `X_cleaned.csv` file with 54 high-quality features, ready for **Phase 3: Feature Engineering**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_credit_risk)",
   "language": "python",
   "name": "venv_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
