{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Imports and Load Pruned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported for Phase 3.\n",
      "Loading features from: /Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/data/processed/X_cleaned.csv\n",
      "Loading target from: /Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/data/processed/y_target.csv\n",
      "\n",
      "--- Pruned Data Loaded Successfully ---\n",
      "X shape: (51336, 54)\n",
      "y shape: (51336,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# --- Setup ---\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported for Phase 3.\")\n",
    "\n",
    "# --- Load Processed Data (from Phase 2) ---\n",
    "# We use the full, confirmed path from your last output\n",
    "FULL_PATH_TO_PROCESSED = '/Users/yogeshdhaliya/Desktop/DS Learning/11. Projects/Credit-Risk-Prediction/data/processed'\n",
    "\n",
    "X_path = os.path.join(FULL_PATH_TO_PROCESSED, 'X_cleaned.csv')\n",
    "y_path = os.path.join(FULL_PATH_TO_PROCESSED, 'y_target.csv')\n",
    "\n",
    "print(f\"Loading features from: {X_path}\")\n",
    "print(f\"Loading target from: {y_path}\")\n",
    "\n",
    "try:\n",
    "    X = pd.read_csv(X_path, index_col='PROSPECTID')\n",
    "    y = pd.read_csv(y_path, index_col='PROSPECTID').squeeze('columns')\n",
    "    \n",
    "    print(\"\\n--- Pruned Data Loaded Successfully ---\")\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n[ERROR] File not found. Please double-check the path.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Define Feature Lists (From Phase 2 EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Defining Feature Lists based on EDA ---\n",
      "Ordinal features (1): ['EDUCATION']\n",
      "Nominal features (4): ['MARITALSTATUS', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']\n",
      "Num (impute 0) features (11): ['tot_enq', 'CC_enq', 'CC_enq_L6m', 'CC_enq_L12m', 'PL_enq', 'PL_enq_L6m', 'PL_enq_L12m', 'time_since_recent_enq', 'enq_L12m', 'enq_L6m', 'enq_L3m']\n",
      "Num (impute median) features (2): ['Age_Oldest_TL', 'Age_Newest_TL']\n",
      "Num (no impute) features (36): ['AGE', 'NETMONTHLYINCOME', 'Time_With_Curr_Empr', 'pct_of_active_TLs_ever', 'pct_opened_TLs_L6m_of_L12m', 'CC_Flag', 'PL_Flag', 'pct_PL_enq_L6m_of_L12m', 'pct_CC_enq_L6m_of_L12m', 'pct_PL_enq_L6m_of_ever', 'pct_CC_enq_L6m_of_ever', 'HL_Flag', 'GL_Flag', 'Total_TL', 'Tot_Closed_TL', 'Tot_Active_TL', 'Total_TL_opened_L6M', 'Tot_TL_closed_L6M', 'pct_tl_open_L6M', 'pct_tl_closed_L6M', 'pct_active_tl', 'pct_closed_tl', 'Total_TL_opened_L12M', 'Tot_TL_closed_L12M', 'pct_tl_open_L12M', 'pct_tl_closed_L12M', 'Tot_Missed_Pmnt', 'Auto_TL', 'CC_TL', 'Consumer_TL', 'Gold_TL', 'Home_TL', 'PL_TL', 'Secured_TL', 'Unsecured_TL', 'Other_TL']\n",
      "\n",
      "Total features categorized: 54 / 54\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Defining Feature Lists based on EDA ---\")\n",
    "\n",
    "# --- 1. Categorical Features (Finding 3) ---\n",
    "# Based on your expert domain knowledge\n",
    "EDUCATION_MAP = [\n",
    "    'OTHERS',           # 0\n",
    "    'SSC',              # 1\n",
    "    '12TH',             # 2\n",
    "    'UNDER GRADUATE',   # 3\n",
    "    'GRADUATE',         # 4\n",
    "    'POST-GRADUATE',    # 5\n",
    "    'PROFESSIONAL'      # 6\n",
    "]\n",
    "ORDINAL_FEATURE = ['EDUCATION']\n",
    "NOMINAL_FEATURES = [\n",
    "    'MARITALSTATUS', \n",
    "    'GENDER', \n",
    "    'last_prod_enq2', \n",
    "    'first_prod_enq2'\n",
    "]\n",
    "\n",
    "# --- 2. Numerical Features (from Missing Data Analysis) ---\n",
    "# Group 3: Systematic Missingness -> Impute with 0\n",
    "NUM_IMPUTE_ZERO_FEATURES = [\n",
    "    'tot_enq', 'CC_enq', 'CC_enq_L6m', 'CC_enq_L12m', 'PL_enq', \n",
    "    'PL_enq_L6m', 'PL_enq_L12m', 'time_since_recent_enq', \n",
    "    'enq_L12m', 'enq_L6m', 'enq_L3m'\n",
    "]\n",
    "\n",
    "# Group 4: Minor Missingness -> Impute with Median\n",
    "NUM_IMPUTE_MEDIAN_FEATURES = [\n",
    "    'Age_Oldest_TL', \n",
    "    'Age_Newest_TL'\n",
    "]\n",
    "\n",
    "# --- 3. Consolidate All Lists ---\n",
    "# Get all remaining numerical columns that need no imputation\n",
    "all_used_cols = (\n",
    "    ORDINAL_FEATURE + \n",
    "    NOMINAL_FEATURES + \n",
    "    NUM_IMPUTE_ZERO_FEATURES + \n",
    "    NUM_IMPUTE_MEDIAN_FEATURES\n",
    ")\n",
    "\n",
    "NUM_NO_IMPUTE_FEATURES = [\n",
    "    col for col in X.columns \n",
    "    if col not in all_used_cols\n",
    "]\n",
    "\n",
    "print(f\"Ordinal features (1): {ORDINAL_FEATURE}\")\n",
    "print(f\"Nominal features (4): {NOMINAL_FEATURES}\")\n",
    "print(f\"Num (impute 0) features (11): {NUM_IMPUTE_ZERO_FEATURES}\")\n",
    "print(f\"Num (impute median) features (2): {NUM_IMPUTE_MEDIAN_FEATURES}\")\n",
    "print(f\"Num (no impute) features ({len(NUM_NO_IMPUTE_FEATURES)}): {NUM_NO_IMPUTE_FEATURES}\")\n",
    "print(f\"\\nTotal features categorized: {1+4+11+2+len(NUM_NO_IMPUTE_FEATURES)} / {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Build Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Building Preprocessing Pipelines (Corrected) ---\n",
      "ColumnTransformer 'preprocessor' created successfully with 'drop=first'.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Building Preprocessing Pipelines (Corrected) ---\")\n",
    "\n",
    "# --- 1. Ordinal Pipeline (Finding 3) ---\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(categories=[EDUCATION_MAP], handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "# --- 2. Nominal Pipeline (Finding 3 - CORRECTED) ---\n",
    "# We add 'drop=first' to prevent the Dummy Variable Trap\n",
    "# which was causing our VIFs to explode.\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first')) # <-- FIX IS HERE\n",
    "])\n",
    "\n",
    "# --- 3. Numerical Pipelines (from EDA & Finding 2) ---\n",
    "num_zero_impute_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "num_median_impute_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "num_no_impute_transformer = Pipeline(steps=[\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# --- 4. Create the Master ColumnTransformer ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ordinal', ordinal_transformer, ORDINAL_FEATURE),\n",
    "        ('nominal', nominal_transformer, NOMINAL_FEATURES),\n",
    "        ('num_impute_zero', num_zero_impute_transformer, NUM_IMPUTE_ZERO_FEATURES),\n",
    "        ('num_impute_median', num_median_impute_transformer, NUM_IMPUTE_MEDIAN_FEATURES),\n",
    "        ('num_no_impute', num_no_impute_transformer, NUM_NO_IMPUTE_FEATURES)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "print(\"ColumnTransformer 'preprocessor' created successfully with 'drop=first'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Apply Preprocessor & Run VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Applying 'preprocessor' to X ---\n",
      "Data processed. New shape with OHE (k-1): (51336, 62)\n",
      "Head of processed data:\n",
      "            EDUCATION  MARITALSTATUS_Single  GENDER_M  last_prod_enq2_CC  \\\n",
      "PROSPECTID                                                                 \n",
      "1                 2.0                   0.0       1.0                0.0   \n",
      "2                 4.0                   1.0       0.0                0.0   \n",
      "3                 1.0                   0.0       1.0                0.0   \n",
      "4                 1.0                   0.0       1.0                0.0   \n",
      "5                 5.0                   0.0       1.0                0.0   \n",
      "\n",
      "            last_prod_enq2_ConsumerLoan  last_prod_enq2_HL  last_prod_enq2_PL  \\\n",
      "PROSPECTID                                                                      \n",
      "1                                   0.0                0.0                1.0   \n",
      "2                                   1.0                0.0                0.0   \n",
      "3                                   1.0                0.0                0.0   \n",
      "4                                   0.0                0.0                0.0   \n",
      "5                                   0.0                0.0                0.0   \n",
      "\n",
      "            last_prod_enq2_others  first_prod_enq2_CC  \\\n",
      "PROSPECTID                                              \n",
      "1                             0.0                 0.0   \n",
      "2                             0.0                 0.0   \n",
      "3                             0.0                 0.0   \n",
      "4                             1.0                 0.0   \n",
      "5                             0.0                 0.0   \n",
      "\n",
      "            first_prod_enq2_ConsumerLoan  first_prod_enq2_HL  \\\n",
      "PROSPECTID                                                     \n",
      "1                                    0.0                 0.0   \n",
      "2                                    1.0                 0.0   \n",
      "3                                    0.0                 0.0   \n",
      "4                                    0.0                 0.0   \n",
      "5                                    0.0                 0.0   \n",
      "\n",
      "            first_prod_enq2_PL  first_prod_enq2_others  tot_enq  CC_enq  \\\n",
      "PROSPECTID                                                                \n",
      "1                          1.0                     0.0      0.6     0.0   \n",
      "2                          0.0                     0.0     -0.4     0.0   \n",
      "3                          0.0                     1.0      0.2     0.0   \n",
      "4                          0.0                     1.0     -0.6     0.0   \n",
      "5                          0.0                     0.0     -0.4     0.0   \n",
      "\n",
      "            CC_enq_L6m  CC_enq_L12m  PL_enq  PL_enq_L6m  PL_enq_L12m  \\\n",
      "PROSPECTID                                                             \n",
      "1                  0.0          0.0     6.0         0.0          0.0   \n",
      "2                  0.0          0.0     0.0         0.0          0.0   \n",
      "3                  0.0          0.0     0.0         0.0          0.0   \n",
      "4                  0.0          0.0     0.0         0.0          0.0   \n",
      "5                  0.0          0.0     0.0         0.0          0.0   \n",
      "\n",
      "            time_since_recent_enq  enq_L12m  enq_L6m  enq_L3m  Age_Oldest_TL  \\\n",
      "PROSPECTID                                                                     \n",
      "1                        2.135246 -0.333333     -0.5      0.0           0.78   \n",
      "2                        0.672131  0.000000     -0.5      0.0          -0.52   \n",
      "3                        2.221311 -0.333333     -0.5      0.0           0.28   \n",
      "4                       -0.184426 -0.333333     -0.5      0.0          -0.56   \n",
      "5                       16.008197 -0.333333     -0.5      0.0           1.96   \n",
      "\n",
      "            Age_Newest_TL       AGE  NETMONTHLYINCOME  Time_With_Curr_Empr  \\\n",
      "PROSPECTID                                                                   \n",
      "1                0.769231  1.333333          2.333333             0.300000   \n",
      "2               -0.076923 -0.750000         -0.333333            -0.614286   \n",
      "3               -0.461538  0.666667         -1.915167             1.400000   \n",
      "4               -0.230769  0.166667         -1.083333             2.185714   \n",
      "5                1.846154  1.333333         -0.666667            -0.257143   \n",
      "\n",
      "            pct_of_active_TLs_ever  pct_opened_TLs_L6m_of_L12m  CC_Flag  \\\n",
      "PROSPECTID                                                                \n",
      "1                        -0.474667                    0.000000      0.0   \n",
      "2                         0.592000                    0.000000      0.0   \n",
      "3                         0.592000                    0.777605      0.0   \n",
      "4                         0.592000                    1.555210      0.0   \n",
      "5                        -0.297333                    0.000000      0.0   \n",
      "\n",
      "            PL_Flag  pct_PL_enq_L6m_of_L12m  pct_CC_enq_L6m_of_L12m  \\\n",
      "PROSPECTID                                                            \n",
      "1               1.0                     0.0                     0.0   \n",
      "2               0.0                     0.0                     0.0   \n",
      "3               0.0                     0.0                     0.0   \n",
      "4               0.0                     0.0                     0.0   \n",
      "5               0.0                     0.0                     0.0   \n",
      "\n",
      "            pct_PL_enq_L6m_of_ever  pct_CC_enq_L6m_of_ever  HL_Flag  GL_Flag  \\\n",
      "PROSPECTID                                                                     \n",
      "1                              0.0                     0.0      1.0      0.0   \n",
      "2                              0.0                     0.0      0.0      0.0   \n",
      "3                              0.0                     0.0      1.0      0.0   \n",
      "4                              0.0                     0.0      0.0      0.0   \n",
      "5                              0.0                     0.0      0.0      0.0   \n",
      "\n",
      "            Total_TL  Tot_Closed_TL  Tot_Active_TL  Total_TL_opened_L6M  \\\n",
      "PROSPECTID                                                                \n",
      "1               0.75       1.000000            0.0                  0.0   \n",
      "2              -0.25      -0.333333            0.0                  0.0   \n",
      "3               1.50      -0.333333            3.5                  1.0   \n",
      "4              -0.25      -0.333333            0.0                  1.0   \n",
      "5               0.25       0.333333            0.0                  0.0   \n",
      "\n",
      "            Tot_TL_closed_L6M  pct_tl_open_L6M  pct_tl_closed_L6M  \\\n",
      "PROSPECTID                                                          \n",
      "1                         0.0         0.000000                0.0   \n",
      "2                         0.0         0.000000                0.0   \n",
      "3                         0.0         0.405844                0.0   \n",
      "4                         0.0         3.246753                0.0   \n",
      "5                         0.0         0.000000                0.0   \n",
      "\n",
      "            pct_active_tl  pct_closed_tl  Total_TL_opened_L12M  \\\n",
      "PROSPECTID                                                       \n",
      "1               -0.474667       0.474667                  -0.5   \n",
      "2                0.592000      -0.592000                   0.0   \n",
      "3                0.592000      -0.592000                   0.5   \n",
      "4                0.592000      -0.592000                   0.0   \n",
      "5               -0.297333       0.297333                  -0.5   \n",
      "\n",
      "            Tot_TL_closed_L12M  pct_tl_open_L12M  pct_tl_closed_L12M  \\\n",
      "PROSPECTID                                                             \n",
      "1                          0.0         -0.444000                 0.0   \n",
      "2                          0.0          0.889333                 0.0   \n",
      "3                          0.0         -0.110667                 0.0   \n",
      "4                          0.0          0.889333                 0.0   \n",
      "5                          0.0         -0.444000                 0.0   \n",
      "\n",
      "            Tot_Missed_Pmnt  Auto_TL  CC_TL  Consumer_TL  Gold_TL  Home_TL  \\\n",
      "PROSPECTID                                                                   \n",
      "1                       0.0      0.0    0.0          0.0      1.0      0.0   \n",
      "2                       0.0      0.0    0.0          1.0      0.0      0.0   \n",
      "3                       1.0      1.0    0.0          6.0      1.0      0.0   \n",
      "4                       1.0      0.0    0.0          0.0      0.0      0.0   \n",
      "5                       0.0      1.0    0.0          0.0      0.0      0.0   \n",
      "\n",
      "            PL_TL  Secured_TL  Unsecured_TL  Other_TL  \n",
      "PROSPECTID                                             \n",
      "1             4.0    0.000000           1.5       0.0  \n",
      "2             0.0   -0.333333           0.0       0.0  \n",
      "3             0.0    0.333333           2.5       0.0  \n",
      "4             0.0   -0.333333           0.0       1.0  \n",
      "5             0.0    0.666667          -0.5       2.0  \n",
      "\n",
      "--- Calculating Variance Inflation Factor (VIF) ---\n",
      "VIF results (Top 15):\n",
      "                   feature           VIF\n",
      "61                Other_TL           inf\n",
      "54                   CC_TL           inf\n",
      "41           Tot_Active_TL           inf\n",
      "58                   PL_TL           inf\n",
      "57                 Home_TL           inf\n",
      "55             Consumer_TL           inf\n",
      "53                 Auto_TL           inf\n",
      "59              Secured_TL  3.810349e+06\n",
      "60            Unsecured_TL  8.230814e+05\n",
      "56                 Gold_TL  5.017293e+05\n",
      "40           Tot_Closed_TL  2.412826e+05\n",
      "47           pct_closed_tl  1.887359e+05\n",
      "46           pct_active_tl  1.437601e+05\n",
      "39                Total_TL  4.229967e+04\n",
      "29  pct_of_active_TLs_ever  2.568237e+04\n",
      "\n",
      "\n",
      "VIF results (Bottom 15):\n",
      "                  feature       VIF\n",
      "24          Age_Oldest_TL  2.454069\n",
      "32                PL_Flag  2.367959\n",
      "8      first_prod_enq2_CC  2.196286\n",
      "25          Age_Newest_TL  2.170697\n",
      "52        Tot_Missed_Pmnt  2.113065\n",
      "10     first_prod_enq2_HL  1.855603\n",
      "5       last_prod_enq2_HL  1.823231\n",
      "37                HL_Flag  1.757963\n",
      "26                    AGE  1.714109\n",
      "1    MARITALSTATUS_Single  1.378237\n",
      "20  time_since_recent_enq  1.291005\n",
      "28    Time_With_Curr_Empr  1.279563\n",
      "0               EDUCATION  1.087193\n",
      "27       NETMONTHLYINCOME  1.068085\n",
      "2                GENDER_M  1.056672\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Apply the Preprocessing Pipeline ---\n",
    "print(\"\\n--- Applying 'preprocessor' to X ---\")\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# --- 2. Get Feature Names After Transformation ---\n",
    "feature_names = (\n",
    "    ORDINAL_FEATURE +\n",
    "    preprocessor.named_transformers_['nominal'].named_steps['encoder'].get_feature_names_out(NOMINAL_FEATURES).tolist() +\n",
    "    NUM_IMPUTE_ZERO_FEATURES +\n",
    "    NUM_IMPUTE_MEDIAN_FEATURES +\n",
    "    NUM_NO_IMPUTE_FEATURES\n",
    ")\n",
    "\n",
    "X_processed_df = pd.DataFrame(X_processed, columns=feature_names, index=X.index)\n",
    "\n",
    "print(f\"Data processed. New shape with OHE (k-1): {X_processed_df.shape}\")\n",
    "print(\"Head of processed data:\")\n",
    "print(X_processed_df.head())\n",
    "\n",
    "# --- 3. Calculate VIF (Validate Finding 2) ---\n",
    "print(\"\\n--- Calculating Variance Inflation Factor (VIF) ---\")\n",
    "\n",
    "# VIF function\n",
    "def calculate_vif(df):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = df.columns\n",
    "    # Adding a constant column for VIF calculation is a robust practice\n",
    "    df_with_const = df.copy()\n",
    "    df_with_const['const'] = 1\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df_with_const.values, i) for i in range(len(df.columns))]\n",
    "    return vif_data.sort_values(by='VIF', ascending=False)\n",
    "\n",
    "# Run VIF calculation\n",
    "vif_results = calculate_vif(X_processed_df)\n",
    "\n",
    "print(\"VIF results (Top 15):\")\n",
    "print(vif_results.head(15))\n",
    "\n",
    "print(\"\\n\\nVIF results (Bottom 15):\")\n",
    "print(vif_results.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF_DROP_COLS = [\n",
    "    # Redundant \"Total\" columns (composites)\n",
    "    'Total_TL',\n",
    "    'Secured_TL',\n",
    "    'Unsecured_TL',\n",
    "    \n",
    "    # Redundant \"Status\" columns (we are keeping \"by type\" instead)\n",
    "    'Tot_Active_TL',\n",
    "    'Tot_Closed_TL',\n",
    "    \n",
    "    # Redundant \"Percentage\" columns (ratios of the above)\n",
    "    'pct_active_tl',\n",
    "    'pct_closed_tl',\n",
    "    'pct_of_active_TLs_ever'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Redefine X and Re-build the Entire Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PHASE 3: FINAL FEATURE SELECTION (Fixing Finding 2) ---\n",
      "Original X shape: (51336, 54)\n",
      "Dropping 8 columns due to high VIF: ['Total_TL', 'Secured_TL', 'Unsecured_TL', 'Tot_Active_TL', 'Tot_Closed_TL', 'pct_active_tl', 'pct_closed_tl', 'pct_of_active_TLs_ever']\n",
      "New X_final_features shape: (51336, 46)\n",
      "\n",
      "--- Re-defining Feature Lists ---\n",
      "Total features categorized: 46 / 46\n",
      "\n",
      "--- Re-building Preprocessor ---\n",
      "Final 'final_preprocessor' created.\n",
      "\n",
      "--- Applying Final Preprocessor & Running VIF Check ---\n",
      "Final processed data shape: (51336, 54)\n",
      "\n",
      "--- Final VIF Calculation (Validation) ---\n",
      "VIF calculation successful.\n",
      "\n",
      "FINAL VIF results (Top 10):\n",
      "                   feature        VIF\n",
      "21                enq_L12m  25.762880\n",
      "22                 enq_L6m  22.851271\n",
      "32  pct_PL_enq_L6m_of_L12m  20.019594\n",
      "34  pct_PL_enq_L6m_of_ever  19.442076\n",
      "33  pct_CC_enq_L6m_of_L12m  18.826684\n",
      "19             PL_enq_L12m  17.045485\n",
      "35  pct_CC_enq_L6m_of_ever  16.886400\n",
      "13                 tot_enq  12.668333\n",
      "18              PL_enq_L6m  12.098854\n",
      "16             CC_enq_L12m  11.568158\n",
      "\n",
      "FINAL VIF results (Bottom 10):\n",
      "                  feature       VIF\n",
      "47                Auto_TL  1.639888\n",
      "50                Gold_TL  1.608830\n",
      "53               Other_TL  1.599490\n",
      "36                HL_Flag  1.514689\n",
      "1    MARITALSTATUS_Single  1.377171\n",
      "20  time_since_recent_enq  1.288013\n",
      "28    Time_With_Curr_Empr  1.279367\n",
      "0               EDUCATION  1.086294\n",
      "27       NETMONTHLYINCOME  1.068080\n",
      "2                GENDER_M  1.056709\n",
      "\n",
      "--- PHASE 3: FEATURE SELECTION COMPLETE ---\n",
      "We now have a clean, preprocessed, and multicollinearity-free feature set.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "print(\"\\n--- PHASE 3: FINAL FEATURE SELECTION (Fixing Finding 2) ---\")\n",
    "\n",
    "# --- 1. Define VIF \"Kill List\" based on our analysis ---\n",
    "VIF_DROP_COLS = [\n",
    "    # Redundant \"Total\" columns (composites)\n",
    "    'Total_TL',\n",
    "    'Secured_TL',\n",
    "    'Unsecured_TL',\n",
    "    \n",
    "    # Redundant \"Status\" columns (we are keeping \"by type\" instead)\n",
    "    'Tot_Active_TL',\n",
    "    'Tot_Closed_TL',\n",
    "    \n",
    "    # Redundant \"Percentage\" columns (ratios of the above)\n",
    "    'pct_active_tl',\n",
    "    'pct_closed_tl',\n",
    "    'pct_of_active_TLs_ever'\n",
    "]\n",
    "print(f\"Original X shape: {X.shape}\")\n",
    "print(f\"Dropping {len(VIF_DROP_COLS)} columns due to high VIF: {VIF_DROP_COLS}\")\n",
    "\n",
    "# --- 2. Create Final Feature Set ---\n",
    "X_final_features = X.drop(columns=VIF_DROP_COLS)\n",
    "print(f\"New X_final_features shape: {X_final_features.shape}\") # Should be 46 columns\n",
    "\n",
    "# --- 3. Re-Define Feature Lists ---\n",
    "print(\"\\n--- Re-defining Feature Lists ---\")\n",
    "\n",
    "# Categorical lists are unchanged\n",
    "EDUCATION_MAP = [\n",
    "    'OTHERS', 'SSC', '12TH', 'UNDER GRADUATE', \n",
    "    'GRADUATE', 'POST-GRADUATE', 'PROFESSIONAL'\n",
    "]\n",
    "ORDINAL_FEATURE = ['EDUCATION']\n",
    "NOMINAL_FEATURES = [\n",
    "    'MARITALSTATUS', 'GENDER', 'last_prod_enq2', 'first_prod_enq2'\n",
    "]\n",
    "\n",
    "# Numerical lists must be rebuilt from X_final_features\n",
    "NUM_IMPUTE_ZERO_FEATURES = [\n",
    "    'tot_enq', 'CC_enq', 'CC_enq_L6m', 'CC_enq_L12m', 'PL_enq', \n",
    "    'PL_enq_L6m', 'PL_enq_L12m', 'time_since_recent_enq', \n",
    "    'enq_L12m', 'enq_L6m', 'enq_L3m'\n",
    "]\n",
    "NUM_IMPUTE_MEDIAN_FEATURES = ['Age_Oldest_TL', 'Age_Newest_TL']\n",
    "\n",
    "all_used_cols = (\n",
    "    ORDINAL_FEATURE + NOMINAL_FEATURES + \n",
    "    NUM_IMPUTE_ZERO_FEATURES + NUM_IMPUTE_MEDIAN_FEATURES\n",
    ")\n",
    "NUM_NO_IMPUTE_FEATURES = [\n",
    "    col for col in X_final_features.columns if col not in all_used_cols\n",
    "]\n",
    "\n",
    "print(f\"Total features categorized: {len(all_used_cols) + len(NUM_NO_IMPUTE_FEATURES)} / {X_final_features.shape[1]}\")\n",
    "\n",
    "# --- 4. Re-Build Preprocessing Pipeline ---\n",
    "print(\"\\n--- Re-building Preprocessor ---\")\n",
    "# (Pipelines are identical, just the feature lists have changed)\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(categories=[EDUCATION_MAP], handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first'))\n",
    "])\n",
    "\n",
    "num_zero_impute_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "num_median_impute_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "num_no_impute_transformer = Pipeline(steps=[\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# Re-build the master ColumnTransformer\n",
    "final_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ordinal', ordinal_transformer, ORDINAL_FEATURE),\n",
    "        ('nominal', nominal_transformer, NOMINAL_FEATURES),\n",
    "        ('num_impute_zero', num_zero_impute_transformer, NUM_IMPUTE_ZERO_FEATURES),\n",
    "        ('num_impute_median', num_median_impute_transformer, NUM_IMPUTE_MEDIAN_FEATURES),\n",
    "        ('num_no_impute', num_no_impute_transformer, NUM_NO_IMPUTE_FEATURES)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "print(\"Final 'final_preprocessor' created.\")\n",
    "\n",
    "# --- 5. Apply Final Preprocessor & Run VIF (Validation) ---\n",
    "print(\"\\n--- Applying Final Preprocessor & Running VIF Check ---\")\n",
    "\n",
    "# Apply the new preprocessor to the new X dataframe\n",
    "X_processed_final = final_preprocessor.fit_transform(X_final_features)\n",
    "\n",
    "# Get the new final feature names\n",
    "final_feature_names = (\n",
    "    ORDINAL_FEATURE +\n",
    "    final_preprocessor.named_transformers_['nominal'].named_steps['encoder'].get_feature_names_out(NOMINAL_FEATURES).tolist() +\n",
    "    NUM_IMPUTE_ZERO_FEATURES +\n",
    "    NUM_IMPUTE_MEDIAN_FEATURES +\n",
    "    NUM_NO_IMPUTE_FEATURES\n",
    ")\n",
    "\n",
    "# Create the final processed DataFrame for VIF check\n",
    "X_processed_final_df = pd.DataFrame(\n",
    "    X_processed_final, \n",
    "    columns=final_feature_names, \n",
    "    index=X_final_features.index\n",
    ")\n",
    "\n",
    "print(f\"Final processed data shape: {X_processed_final_df.shape}\") # Should be 54 columns\n",
    "\n",
    "# --- 6. Final VIF Calculation ---\n",
    "print(\"\\n--- Final VIF Calculation (Validation) ---\")\n",
    "\n",
    "def calculate_vif(df):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = df.columns\n",
    "    # Add constant for VIF\n",
    "    df_with_const = df.copy()\n",
    "    df_with_const['const'] = 1\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df_with_const.values, i) for i in range(len(df.columns))]\n",
    "    return vif_data.sort_values(by='VIF', ascending=False)\n",
    "\n",
    "try:\n",
    "    final_vif_results = calculate_vif(X_processed_final_df)\n",
    "    print(\"VIF calculation successful.\")\n",
    "    \n",
    "    print(\"\\nFINAL VIF results (Top 10):\")\n",
    "    print(final_vif_results.head(10))\n",
    "\n",
    "    print(\"\\nFINAL VIF results (Bottom 10):\")\n",
    "    print(final_vif_results.tail(10))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n[ERROR] An error occurred during final VIF calculation:\")\n",
    "    print(e)\n",
    "    print(\"This may be due to remaining collinearity. Please check the feature lists.\")\n",
    "\n",
    "print(\"\\n--- PHASE 3: FEATURE SELECTION COMPLETE ---\")\n",
    "print(\"We now have a clean, preprocessed, and multicollinearity-free feature set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: Final VIF Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PHASE 3: FINAL VIF PRUNING (Round 2) ---\n",
      "Starting with 46 features from last step.\n",
      "Dropping 8 more columns due to high VIF: ['tot_enq', 'enq_L12m', 'PL_enq_L12m', 'CC_enq_L12m', 'pct_PL_enq_L6m_of_L12m', 'pct_PL_enq_L6m_of_ever', 'pct_CC_enq_L6m_of_L12m', 'pct_CC_enq_L6m_of_ever']\n",
      "Absolute Final Feature Set shape: (51336, 38)\n",
      "\n",
      "--- Re-defining Final Feature Lists ---\n",
      "Final Num (impute 0) features (7): ['CC_enq', 'CC_enq_L6m', 'PL_enq', 'PL_enq_L6m', 'time_since_recent_enq', 'enq_L6m', 'enq_L3m']\n",
      "Final Num (no impute) features (24): ['AGE', 'NETMONTHLYINCOME', 'Time_With_Curr_Empr', 'pct_opened_TLs_L6m_of_L12m', 'CC_Flag', 'PL_Flag', 'HL_Flag', 'GL_Flag', 'Total_TL_opened_L6M', 'Tot_TL_closed_L6M', 'pct_tl_open_L6M', 'pct_tl_closed_L6M', 'Total_TL_opened_L12M', 'Tot_TL_closed_L12M', 'pct_tl_open_L12M', 'pct_tl_closed_L12M', 'Tot_Missed_Pmnt', 'Auto_TL', 'CC_TL', 'Consumer_TL', 'Gold_TL', 'Home_TL', 'PL_TL', 'Other_TL']\n",
      "Total features categorized: 38 / 38\n",
      "\n",
      "--- Re-building Final Preprocessor ---\n",
      "Final 'final_preprocessor' created.\n",
      "\n",
      "--- Applying Final Preprocessor & Running FINAL VIF Check ---\n",
      "Final processed data shape: (51336, 46)\n",
      "\n",
      "--- Final VIF Calculation (Validation) ---\n",
      "\n",
      "FINAL VIF results (Top 10):\n",
      "                        feature        VIF\n",
      "7         last_prod_enq2_others  10.280822\n",
      "34         Total_TL_opened_L12M  10.252119\n",
      "4   last_prod_enq2_ConsumerLoan  10.024389\n",
      "18                      enq_L6m   9.229132\n",
      "30          Total_TL_opened_L6M   8.045762\n",
      "35           Tot_TL_closed_L12M   7.751986\n",
      "31            Tot_TL_closed_L6M   6.569076\n",
      "6             last_prod_enq2_PL   6.377088\n",
      "12       first_prod_enq2_others   5.738566\n",
      "32              pct_tl_open_L6M   5.481952\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "print(\"\\n--- PHASE 3: FINAL VIF PRUNING (Round 2) ---\")\n",
    "\n",
    "# --- 1. Define Final Enquiry \"Kill List\" ---\n",
    "VIF_DROP_COLS_2 = [\n",
    "    # Redundant \"Total\"\n",
    "    'tot_enq', \n",
    "    \n",
    "    # Redundant \"12-Month\" columns (we keep the 6-month)\n",
    "    'enq_L12m', \n",
    "    'PL_enq_L12m', \n",
    "    'CC_enq_L12m',\n",
    "    \n",
    "    # Redundant \"Percentage\" ratios\n",
    "    'pct_PL_enq_L6m_of_L12m', \n",
    "    'pct_PL_enq_L6m_of_ever', \n",
    "    'pct_CC_enq_L6m_of_L12m', \n",
    "    'pct_CC_enq_L6m_of_ever'\n",
    "]\n",
    "\n",
    "print(f\"Starting with {X_final_features.shape[1]} features from last step.\")\n",
    "print(f\"Dropping {len(VIF_DROP_COLS_2)} more columns due to high VIF: {VIF_DROP_COLS_2}\")\n",
    "\n",
    "# --- 2. Create Absolute Final Feature Set ---\n",
    "# We drop these from 'X_final_features' (our 46-col set)\n",
    "X_final_final_features = X_final_features.drop(columns=VIF_DROP_COLS_2)\n",
    "print(f\"Absolute Final Feature Set shape: {X_final_final_features.shape}\") # Should be 38 columns\n",
    "\n",
    "# --- 3. Re-Define Feature Lists (Final Time) ---\n",
    "print(\"\\n--- Re-defining Final Feature Lists ---\")\n",
    "\n",
    "# Categorical lists are unchanged\n",
    "EDUCATION_MAP = [\n",
    "    'OTHERS', 'SSC', '12TH', 'UNDER GRADUATE', \n",
    "    'GRADUATE', 'POST-GRADUATE', 'PROFESSIONAL'\n",
    "]\n",
    "ORDINAL_FEATURE = ['EDUCATION']\n",
    "NOMINAL_FEATURES = [\n",
    "    'MARITALSTATUS', 'GENDER', 'last_prod_enq2', 'first_prod_enq2'\n",
    "]\n",
    "\n",
    "# Numerical lists must be rebuilt from X_final_final_features\n",
    "NUM_IMPUTE_ZERO_FEATURES = [\n",
    "    'CC_enq', 'CC_enq_L6m', 'PL_enq', 'PL_enq_L6m', \n",
    "    'time_since_recent_enq', 'enq_L6m', 'enq_L3m'\n",
    "]\n",
    "NUM_IMPUTE_MEDIAN_FEATURES = ['Age_Oldest_TL', 'Age_Newest_TL']\n",
    "\n",
    "all_used_cols = (\n",
    "    ORDINAL_FEATURE + NOMINAL_FEATURES + \n",
    "    NUM_IMPUTE_ZERO_FEATURES + NUM_IMPUTE_MEDIAN_FEATURES\n",
    ")\n",
    "NUM_NO_IMPUTE_FEATURES = [\n",
    "    col for col in X_final_final_features.columns if col not in all_used_cols\n",
    "]\n",
    "\n",
    "print(f\"Final Num (impute 0) features (7): {NUM_IMPUTE_ZERO_FEATURES}\")\n",
    "print(f\"Final Num (no impute) features ({len(NUM_NO_IMPUTE_FEATURES)}): {NUM_NO_IMPUTE_FEATURES}\")\n",
    "print(f\"Total features categorized: {len(all_used_cols) + len(NUM_NO_IMPUTE_FEATURES)} / {X_final_final_features.shape[1]}\")\n",
    "\n",
    "\n",
    "# --- 4. Re-Build Final Preprocessing Pipeline ---\n",
    "print(\"\\n--- Re-building Final Preprocessor ---\")\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(categories=[EDUCATION_MAP], handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first'))\n",
    "])\n",
    "num_zero_impute_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "num_median_impute_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "num_no_impute_transformer = Pipeline(steps=[\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# Re-build the master ColumnTransformer\n",
    "final_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ordinal', ordinal_transformer, ORDINAL_FEATURE),\n",
    "        ('nominal', nominal_transformer, NOMINAL_FEATURES),\n",
    "        ('num_impute_zero', num_zero_impute_transformer, NUM_IMPUTE_ZERO_FEATURES),\n",
    "        ('num_impute_median', num_median_impute_transformer, NUM_IMPUTE_MEDIAN_FEATURES),\n",
    "        ('num_no_impute', num_no_impute_transformer, NUM_NO_IMPUTE_FEATURES)\n",
    "    ],\n",
    "    remainder='passthrough' # This should be empty\n",
    ")\n",
    "print(\"Final 'final_preprocessor' created.\")\n",
    "\n",
    "# --- 5. Apply Final Preprocessor & Run VIF (Final Validation) ---\n",
    "print(\"\\n--- Applying Final Preprocessor & Running FINAL VIF Check ---\")\n",
    "\n",
    "X_processed_final = final_preprocessor.fit_transform(X_final_final_features)\n",
    "final_feature_names = (\n",
    "    ORDINAL_FEATURE +\n",
    "    final_preprocessor.named_transformers_['nominal'].named_steps['encoder'].get_feature_names_out(NOMINAL_FEATURES).tolist() +\n",
    "    NUM_IMPUTE_ZERO_FEATURES +\n",
    "    NUM_IMPUTE_MEDIAN_FEATURES +\n",
    "    NUM_NO_IMPUTE_FEATURES\n",
    ")\n",
    "X_processed_final_df = pd.DataFrame(\n",
    "    X_processed_final, \n",
    "    columns=final_feature_names, \n",
    "    index=X_final_final_features.index\n",
    ")\n",
    "print(f\"Final processed data shape: {X_processed_final_df.shape}\") # Should be 46 columns\n",
    "\n",
    "# --- 6. Final VIF Calculation ---\n",
    "print(\"\\n--- Final VIF Calculation (Validation) ---\")\n",
    "def calculate_vif(df):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = df.columns\n",
    "    df_with_const = df.copy()\n",
    "    df_with_const['const'] = 1\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df_with_const.values, i) for i in range(len(df.columns))]\n",
    "    return vif_data.sort_values(by='VIF', ascending=False)\n",
    "\n",
    "final_vif_results = calculate_vif(X_processed_final_df)\n",
    "\n",
    "print(\"\\nFINAL VIF results (Top 10):\")\n",
    "print(final_vif_results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase 3: Feature Engineering & Selection**.\n",
    "\n",
    "Our primary goal in this phase was to operationalize our EDA findings by building a robust preprocessing pipeline and, most importantly, rigorously validating and resolving **Finding 2 (Multicollinearity)**.\n",
    "\n",
    "### 1. Building the `ColumnTransformer` (Validating Finding 3)\n",
    "\n",
    "First, we translated all our rules from Phase 2 into a `scikit-learn` `ColumnTransformer`:\n",
    "\n",
    "* **Ordinal Features (Finding 3):** We successfully implemented our custom, business-logic mapping for `EDUCATION` (e.g., `'SSC'`: 1, `'12TH'`: 2, ... `'PROFESSIONAL'`: 6) using an `OrdinalEncoder`.\n",
    "* **Nominal Features (Finding 3):** We configured a `OneHotEncoder` for our 4 nominal features. We fixed a critical \"Dummy Variable Trap\" by setting `drop='first'`, which is essential for VIF analysis and modeling.\n",
    "* **Numerical Features (EDA Rules):** We built distinct pipelines to handle all our numerical imputation rules from Phase 2:\n",
    "    * **Impute with 0:** All 11 \"enquiry\" features (where `NaN` means \"zero\").\n",
    "    * **Impute with Median:** The 2 \"Age\" features with minor missingness.\n",
    "    * **Scale:** Applied `RobustScaler` to *all* numerical features to protect our model from the extreme outliers (like in `NETMONTHLYINCOME`) we identified in our EDA.\n",
    "\n",
    "### 2. Iterative VIF Analysis (Resolving Finding 2)\n",
    "\n",
    "This was the core task of Phase 3 and required a rigorous, multi-step process to eliminate all multicollinearity.\n",
    "\n",
    "* **Round 1: Identifying \"Total\" Redundancy**\n",
    "    * Our first VIF run (after fixing the dummy trap) perfectly validated **Finding 2**. We saw `inf` and multi-million VIFs for all the \"total\" and \"status\" columns (e.g., `Total_TL`, `Tot_Active_TL`, `Secured_TL`, `pct_active_tl`).\n",
    "    * **Action:** We **dropped 8 composite/total columns**, adhering to our project rule to \"keep only the most granular features\" (like `Auto_TL`, `CC_TL`, `Home_TL`, etc.).\n",
    "\n",
    "* **Round 2: Identifying \"Enquiry\" Redundancy**\n",
    "    * With the main problem fixed, a second VIF run revealed a more subtle multicollinearity (VIFs ~25) within the \"enquiry\" features.\n",
    "    * The logic was the same: features like `enq_L12m` were redundant with `enq_L6m`, and `tot_enq` was a redundant composite.\n",
    "    * **Action:** We **dropped 8 more redundant \"enquiry\" columns**, keeping only the most granular and recent time windows (e.g., `enq_L6m`, `enq_L3m`, `PL_enq_L6m`).\n",
    "\n",
    "### 3. Final Outcome & Key Deliverables\n",
    "\n",
    "* **Clean VIF:** Our final VIF report is clean. All values are now at an acceptable level (highest ~10.3), proving our feature set is free of destructive multicollinearity.\n",
    "* **Final Feature Set:** We have successfully engineered our final, model-ready feature set. We have rigorously pruned our data from 58 initial features (post-leakage) down to **38 high-quality, granular, and independent features**.\n",
    "* **Key Asset:** The main deliverable of this phase is our `final_preprocessor` object. This `ColumnTransformer` contains all our validated rules for imputation, scaling, and encoding, ready to be the first step in our modeling pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_credit_risk)",
   "language": "python",
   "name": "venv_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
